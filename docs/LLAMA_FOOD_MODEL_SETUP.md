# ü¶ô Llama Food Model Setup - FortyMiles/Llama-3-Diet-Instruct-8B

## Model Info:
- **Model**: FortyMiles/Llama-3-Diet-Instruct-8B
- **Size**: 8B parameters (~16GB)
- **Specialization**: Diet and nutrition planning
- **URL**: https://huggingface.co/FortyMiles/Llama-3-Diet-Instruct-8B

---

## Quick Setup (15 minutes)

### 1Ô∏è‚É£ Open Colab Notebook

1. Go to: https://colab.research.google.com
2. File ‚Üí Upload notebook
3. Upload: `notebooks/Colab_Llama_FoodModel.ipynb`

### 2Ô∏è‚É£ Enable GPU

1. Runtime ‚Üí Change runtime type
2. Select: **T4 GPU** (or **A100** if you have Colab Pro)
3. Click: Save

### 3Ô∏è‚É£ Get Ngrok Token

1. Go to: https://ngrok.com (sign up free)
2. Get token: https://dashboard.ngrok.com/get-started/your-authtoken
3. Copy your authtoken

### 4Ô∏è‚É£ Run Setup Cells

**Cell 1 - Install packages:**
```python
!pip install -q transformers accelerate torch bitsandbytes
!pip install -q flask flask-cors pyngrok
```
‚ñ∂Ô∏è Click Run (takes 30 seconds)

**Cell 2 - Setup Ngrok:**
```python
NGROK_TOKEN = "YOUR_TOKEN_HERE"  # Paste your token
!ngrok authtoken {NGROK_TOKEN}
```
‚ñ∂Ô∏è Update token ‚Üí Click Run

**Cell 3 - Create server:**
‚ñ∂Ô∏è Just click Run (creates server code)

**Cell 4 - Start server:**
‚ö†Ô∏è **This takes 5-10 minutes on first run** (downloads 16GB model)
‚ñ∂Ô∏è Click Run and WAIT...

You'll see:
```
Loading FortyMiles Llama-3 Diet Model...
Loading tokenizer...
Loading model with 4-bit quantization...
Fetching files...
model-00001-of-00004.safetensors: ...
model-00002-of-00004.safetensors: ...
model-00003-of-00004.safetensors: ...
model-00004-of-00004.safetensors: ...
‚úÖ Llama-3 Diet Model loaded successfully on cuda:0!

üåê PUBLIC URL (COPY THIS):
   https://abc123.ngrok.io
```

üìã **COPY THE URL!**

---

## 5Ô∏è‚É£ Update Local Code

On your Windows machine:

1. Open: `D:\Documents\Diet plan\service\recommender_ml\ml_recommender.py`
2. Update lines 14-15:
```python
USE_COLAB = True
COLAB_API_URL = "https://YOUR-NGROK-URL.ngrok.io"  # Paste URL from Colab
```
3. Save file

---

## 6Ô∏è‚É£ Restart Local Server

```powershell
# Stop current server (Ctrl+C)
python -m uvicorn service.api:app --reload --port 8000
```

Watch for:
```
INFO:üåê Using Colab API for model inference
INFO:üì° Colab URL: https://abc123.ngrok.io
INFO:‚úÖ Connected to Colab API
INFO:   Model loaded: True
INFO:   Model name: FortyMiles/Llama-3-Diet-Instruct-8B
INFO:   Device: cuda:0
```

---

## 7Ô∏è‚É£ Test It!

1. http://localhost:8000/choose-system
2. Click: **"Use AI Nutritionist"**
3. Fill profile
4. Submit
5. **Generation takes 10-15 seconds** (larger model, more detailed output)

---

## üìä Model Comparison

| Model | Size | Speed | Quality | Specialization |
|-------|------|-------|---------|----------------|
| Phi-2 (yours) | 2.7B | ‚ö°‚ö°‚ö° Fast (5s) | ‚úÖ Good | General + Fine-tuned |
| **Llama-3 Food** | **8B** | **‚ö°‚ö° Medium (15s)** | **‚úÖ‚úÖ‚úÖ Excellent** | **Diet-specific** |

---

## üîß Why Use Llama Food Model?

‚úÖ **Purpose-built for diet planning** - Trained specifically on nutrition data  
‚úÖ **Better meal suggestions** - Understands food combinations and nutrition  
‚úÖ **More detailed responses** - 8B params vs 2.7B  
‚úÖ **4-bit quantization** - Runs on free T4 GPU  
‚úÖ **No fine-tuning needed** - Already specialized for food  

---

## üéØ Advantages:

1. **Specialized Knowledge**: Model knows about:
   - Indian cuisine
   - Meal timing
   - Portion sizes
   - Nutritional balance
   - Diet types (veg/non-veg/vegan)

2. **Better Structure**: Generates:
   - Complete meal plans
   - Detailed recipes
   - Nutrition breakdowns
   - Cooking instructions

3. **No Training Needed**: Unlike Phi-2, this model is already trained on diet data!

---

## ‚ö†Ô∏è Notes:

- **First load**: 5-10 minutes (downloads 16GB)
- **Subsequent loads**: 2-3 minutes (cached)
- **Colab session**: 12 hours (free tier)
- **Memory**: Uses ~10GB GPU RAM (4-bit quantized)
- **Ngrok URL**: Changes each restart

---

## üí° Pro Tips:

‚úÖ Use **Colab Pro** ($10/month) for:
- A100 GPU (3x faster)
- 24-hour sessions
- Background execution

‚úÖ Model is **cached** after first download - next restart is fast!

‚úÖ Keep Colab tab **open** and **pinned** to prevent disconnection

---

## üéâ Done!

Your specialized Llama-3 diet model is now serving your app via Colab GPU!

**Better diet plans, specialized knowledge, zero training required!** üöÄ
